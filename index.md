---
layout: default
title: "Xiaoyu Yuan | AI Researcher"
---

## Xiaoyu Yuan (Ë¢ÅÁ≠±Èí∞) 

I am Xiaoyu Yuan (Ë¢ÅÁ≠±Èí∞)<span onclick="document.getElementById('name-audio-main').play()" style="cursor: pointer;">üîä</span>
<audio id="name-audio-main" src="{{ "/assets/audio/xiaoyu_yuan.mp3" | relative_url }}"></audio>, a researcher passionate about building **Trustworthy and Explainable AI**. My journey began with a broad curiosity in AI and has since converged on the critical fields of **Trustworthy AI**, **LLM Alignment**, and **Human-in-the-Loop systems**. My hands-on experience ranges from developing **Transformer-based OCR** for ancient scripts to pioneering **Visual SLAM** for medical navigation. These projects taught me that the true challenge isn't just making AI work, but making it work *safely* and *transparently*. This realization is what fuels my current focus on **Reinforcement Learning from Human Feedback (RLHF)** and its alternatives, like DPO.

As I finalize my Master's degree in Computer Science at the **University of Helsinki**, where I was supported by a full scholarship, my work explores how to make AI systems more robust and interpretable. I am now actively seeking a PhD position to contribute to advancing the methodologies for creating AI systems that are not only capable, but also fundamentally aligned with human values.

---
### Education

I am completing my **Master's in Computer Science** at the **University of Helsinki** (2023 - 2025), focusing on the Algorithms and Machine Learning track (GPA: 4.38). This follows my **Bachelor's in Software Engineering** (2019 - 2023), a double degree program jointly conferred by the **University of Oulu** and the **Nanjing Institute of Technology** (GPA: 4.01), which laid a solid foundation in both theoretical principles and practical software development.

---

### Professional Experience

My professional journey has been focused on the practical application and evaluation of AI systems. As a freelance **Human-AI RLHF Evaluation Tasker** with **Outlier.ai**, I specialize in the large-scale preference evaluation of LLM outputs, focusing on critical areas like **hallucination detection, reward modeling, and prompt refinement** to enhance AI safety. This role provides me with firsthand insight into weak supervision signals and the nuances of human-AI text assessment. Previously, as a **Software Test Engineer Intern**, I gained experience in black-box testing and Agile development by analyzing over 2,000 user feedback entries to improve product quality.
